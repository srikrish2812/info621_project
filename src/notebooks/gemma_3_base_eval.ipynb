{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYKpb1ZNHMB5JnS0uUJ7nI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52967c9c5309444dbc7acbe57c19fafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eb3e14882414e14a17810a1a1739918",
              "IPY_MODEL_62aeb6bacb1e46a1ab472356e5f9fd5f",
              "IPY_MODEL_0557a7119b6a4a109a7f5946f31f8547"
            ],
            "layout": "IPY_MODEL_63f1726d65c6469fa2a958da030284ad"
          }
        },
        "7eb3e14882414e14a17810a1a1739918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e48421c80cf43c3b861acdb3864b16d",
            "placeholder": "​",
            "style": "IPY_MODEL_c8cc984eea594c4d8c34784a039d1c04",
            "value": "Formatting test data: 100%"
          }
        },
        "62aeb6bacb1e46a1ab472356e5f9fd5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e0b60ff6a3340bfac3389fa8d99dc97",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9e223282d1e42d6a24a2cec98e1ce78",
            "value": 1319
          }
        },
        "0557a7119b6a4a109a7f5946f31f8547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034ab55c5f9d4f1cb54e4c1c37ce1fe5",
            "placeholder": "​",
            "style": "IPY_MODEL_bb78f7b21e8244e9a20dbdb726a5f4cd",
            "value": " 1319/1319 [00:00&lt;00:00, 23254.19it/s]"
          }
        },
        "63f1726d65c6469fa2a958da030284ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e48421c80cf43c3b861acdb3864b16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cc984eea594c4d8c34784a039d1c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e0b60ff6a3340bfac3389fa8d99dc97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e223282d1e42d6a24a2cec98e1ce78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "034ab55c5f9d4f1cb54e4c1c37ce1fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb78f7b21e8244e9a20dbdb726a5f4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce6fae7689f4480a991b7d8814da0f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed371bd17aa6439e8bbdb717ecc59017",
              "IPY_MODEL_5bb8eac2d67741a499116b2beb8e05f5",
              "IPY_MODEL_c70ca4d07fdf400abba8136e6898f4ee"
            ],
            "layout": "IPY_MODEL_b8873a785b6149618424c9800176fd92"
          }
        },
        "ed371bd17aa6439e8bbdb717ecc59017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f62a15de4aad4d5798c9882864d1f855",
            "placeholder": "​",
            "style": "IPY_MODEL_37620a8476bd482c90af8a413b256c1c",
            "value": "Evaluating Batches (Size 128): 100%"
          }
        },
        "5bb8eac2d67741a499116b2beb8e05f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e485d053c2c43f5b121ce9229bd0d9d",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08bea0ec4eb04158b659dfb732ee288f",
            "value": 11
          }
        },
        "c70ca4d07fdf400abba8136e6898f4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73626a8f24ce440fba6241633d0cbb22",
            "placeholder": "​",
            "style": "IPY_MODEL_627579979b6840a8918e0c006414c820",
            "value": " 11/11 [08:48&lt;00:00, 44.50s/it]"
          }
        },
        "b8873a785b6149618424c9800176fd92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f62a15de4aad4d5798c9882864d1f855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37620a8476bd482c90af8a413b256c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e485d053c2c43f5b121ce9229bd0d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08bea0ec4eb04158b659dfb732ee288f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73626a8f24ce440fba6241633d0cbb22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627579979b6840a8918e0c006414c820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Metrics Evaluation"
      ],
      "metadata": {
        "id": "glmBS9Z9mi_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Framework/ Library Installation"
      ],
      "metadata": {
        "id": "CRQQMQmomq9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs unsloth and other dependencies optimized for colab\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --upgrade transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Z6Zlrbg9pbhL",
        "outputId": "7af71b05-d106-4819-93d7-048d4e82598e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-86g66316/unsloth_31d5b258674c474a93b90633adcc3740\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-86g66316/unsloth_31d5b258674c474a93b90633adcc3740\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 5ce83f272bd9e726b68b0a0452b8b04d32477133\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth_zoo>=2025.4.4 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading unsloth_zoo-2025.4.4-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.51.3)\n",
            "Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.30.2)\n",
            "Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.3)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.20.0)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet]>=0.30.0->unsloth_zoo>=2025.4.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.4.4-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.19-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.4.7-py3-none-any.whl size=262961 sha256=fb1e997c6843958e4f43777e9d0a0aea53d942602409439c5c7634dcb00671fb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k0c2r6lb/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: xxhash, unsloth, shtab, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, hf-xet, hf_transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 hf-xet-1.1.0 hf_transfer-0.1.9 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 shtab-1.7.2 trl-0.15.2 tyro-0.9.19 unsloth-2025.4.7 unsloth_zoo-2025.4.4 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "15e33a7cf7df4532be4554ed9f90172e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "\n",
        "\n",
        "Evaluate the zero-shot performance of unsloth/gemma-3-1b-it-bnb-4bit\n",
        "on the openai/gsm8k dataset.\n",
        "\n",
        "This code below performs the following:\n",
        "1. Imports libraries\n",
        "2. Defines functions to:\n",
        "    - Load the specified Unsloth Gemma model and tokenizer.\n",
        "    - Load and prepare the gsm8k dataset, formatting prompts correctly.\n",
        "    - Extract the final numeric answer from text using regex.\n",
        "    - Run the evaluation loop: generate answers, extract numbers, compare.\n",
        "3. Executes the main evaluation process:\n",
        "    - Loads model and data.\n",
        "    - Runs evaluation (optionally on a subset).\n",
        "    - Prints accuracy results.\n",
        "    - Saves detailed results to a CSV file.\n",
        "    - Generates a simple plot of the accuracy."
      ],
      "metadata": {
        "id": "1osEulCzmgZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unsloth\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings, math"
      ],
      "metadata": {
        "id": "Fa9ISBPemfyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and tokenizer\n",
        "def load_model():\n",
        "    \"\"\"\n",
        "    Load the Gemma 3 1B model with Unsloth optimizations.\n",
        "    Returns the model and tokenizer as a tuple.\n",
        "    \"\"\"\n",
        "    model_name = \"unsloth/gemma-3-1b-it-bnb-4bit\"\n",
        "\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name,\n",
        "        load_in_4bit=True,\n",
        "        device_map=\"auto\", #selects gpu if available\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "    # sets padding token to eos_token if not set already\n",
        "    if tokenizer.pad_token is None:\n",
        "      tokenizer.padding_side=\"left\"\n",
        "      tokenizer.pad_token = tokenizer.eos_token\n",
        "      model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    elif tokenizer.padding_side != \"left\":\n",
        "      print(\"padding side is kept to left for batch generation\")\n",
        "      tokenizer.padding_side=\"left\"\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "iaNVs8HNm-wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(split: str = \"test\"):\n",
        "    \"\"\"\n",
        "    Loads the gsm8k dataset and prepares it for evaluation.\n",
        "\n",
        "    Formats questions into prompts suitable for the Gemma instruction-tuned model\n",
        "    and extracts the final numeric gold answer.\n",
        "\n",
        "    Args:\n",
        "        split (str): The dataset split to load ('test' or 'train').\n",
        "                     Defaults to 'test'.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains:\n",
        "              'prompt': The formatted input prompt for the model.\n",
        "              'gold_answer_numeric': The extracted final numeric answer as a string.\n",
        "              'original_question': The original question text.\n",
        "              'original_answer': The full original answer text with reasoning.\n",
        "    \"\"\"\n",
        "    print(f\"Loading and preparing gsm8k dataset (split: {split})...\")\n",
        "    gsm8k = load_dataset(\"openai/gsm8k\", \"main\")\n",
        "    dataset_split = gsm8k[split]\n",
        "\n",
        "    formatted_data = []\n",
        "    for example in tqdm(dataset_split, desc=f\"Formatting {split} data\"):\n",
        "        question = example[\"question\"].strip()\n",
        "        answer_full = example[\"answer\"].strip()\n",
        "\n",
        "        # Extract the final numeric answer after \"####\"\n",
        "        try:\n",
        "            # Splits by \"####\" and takes the last part using strip function\n",
        "            gold_answer_numeric = re.split(r\"####\\s*\", answer_full)[-1].strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not parse gold answer for question: {question[:50]}... Error: {e}\")\n",
        "            gold_answer_numeric = None\n",
        "\n",
        "        # Formatting the prompt using Gemma's instruction format\n",
        "        # Reference: https://huggingface.co/google/gemma-1.1-2b-it#chat-template\n",
        "        prompt = f\"<start_of_turn>user\\nSolve the following math problem step-by-step:\\n{question}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "        formatted_data.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"gold_answer_numeric\": gold_answer_numeric,\n",
        "            \"original_question\": question,\n",
        "            \"original_answer\": answer_full\n",
        "        })\n",
        "    print(f\"Dataset preparation complete. {len(formatted_data)} examples formatted.\")\n",
        "    return formatted_data"
      ],
      "metadata": {
        "id": "EUO48wvcs01z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # stops gardient computation since we are performing only inference\n",
        "def evaluate_zero_shot(model, tokenizer, dataset: list,batch_size:int=8, max_new_tokens: int = 150, num_samples: int | None = None):\n",
        "    \"\"\"\n",
        "    Evaluates the model's zero-shot performance on the prepared dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The loaded language model (Unsloth optimized).\n",
        "        tokenizer: The tokenizer associated with the model.\n",
        "        batch_size(int): number of examples to process on GPU\n",
        "        dataset (list): The list of formatted data dictionaries from prepare_gsm8k_dataset.\n",
        "        max_new_tokens (int): Maximum number of tokens to generate for the answer.\n",
        "        num_samples (int | None): If set, evaluate only the first 'num_samples'.\n",
        "                                  If None, evaluate the entire dataset.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing evaluation metrics and detailed results:\n",
        "              'accuracy': The exact match accuracy (float).\n",
        "              'correct_count': Number of correctly answered questions (int).\n",
        "              'total_count': Total number of questions evaluated (int).\n",
        "              'results': A list of dictionaries with details for each sample.\n",
        "    \"\"\"\n",
        "    if num_samples is not None and num_samples > 0:\n",
        "        print(f\"Evaluating on the first {num_samples} samples.\")\n",
        "        dataset = dataset[:num_samples]\n",
        "    else:\n",
        "        print(f\"Evaluating on the full dataset ({len(dataset)} samples).\")\n",
        "\n",
        "    correct_count = 0\n",
        "    results_list = []\n",
        "    total_count=len(dataset)\n",
        "\n",
        "    # set pad token to eos token if not set\n",
        "    gen_pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
        "\n",
        "    # number of batches\n",
        "    num_batches = math.ceil(total_count / batch_size)\n",
        "\n",
        "    # Looping through dataset in batches\n",
        "    for i in tqdm(range(num_batches), desc=f\"Evaluating Batches (Size {batch_size})\"):\n",
        "        start_index = i * batch_size\n",
        "        end_index = min((i + 1) * batch_size, total_count)\n",
        "        batch_data = dataset[start_index:end_index]\n",
        "\n",
        "        # prompts and gold answers for the batch\n",
        "        batch_prompts = [example[\"prompt\"] for example in batch_data]\n",
        "        batch_gold_numeric = [example[\"gold_answer_numeric\"] for example in batch_data]\n",
        "\n",
        "        # Tokenizes the batch of prompts\n",
        "        inputs = tokenizer(\n",
        "            batch_prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(model.device)\n",
        "\n",
        "        # generating outputs for the entire batch\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.0,\n",
        "            do_sample=False,\n",
        "            pad_token_id=gen_pad_token_id\n",
        "        )\n",
        "\n",
        "        # Decode generated text for the batch\n",
        "        # We need to decode starting after the input sequence for each item\n",
        "        input_lengths = inputs.input_ids.shape[1] # Length of padded input\n",
        "        # Decode each sequence in the batch individually\n",
        "        generated_texts = tokenizer.batch_decode(outputs[:, input_lengths:], skip_special_tokens=True)\n",
        "\n",
        "        # Handling results for each item in the batch\n",
        "        for j in range(len(batch_data)):\n",
        "            original_example = batch_data[j]\n",
        "            generated_text = generated_texts[j]\n",
        "            gold_numeric = batch_gold_numeric[j]\n",
        "\n",
        "            # Extracting the final number from the generated text\n",
        "            generated_numeric = extract_final_number(generated_text)\n",
        "\n",
        "            # Comparing extracted numbers for exact match\n",
        "            is_correct = False\n",
        "            if gold_numeric is not None and generated_numeric is not None:\n",
        "                try:\n",
        "                    if abs(float(generated_numeric) - float(gold_numeric)) < 1e-6: # Tolerance for float comparison\n",
        "                        is_correct = True\n",
        "                except ValueError:\n",
        "                    if generated_numeric == gold_numeric: # Fallback to string comparison\n",
        "                        is_correct = True\n",
        "\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "\n",
        "            # Store detailed results\n",
        "            results_list.append({\n",
        "                \"question\": original_example[\"original_question\"],\n",
        "                \"prompt\": original_example[\"prompt\"], # Store the original prompt\n",
        "                \"full_gold_answer\": original_example[\"original_answer\"],\n",
        "                \"gold_numeric\": gold_numeric,\n",
        "                \"generated_text\": generated_text,\n",
        "                \"generated_numeric\": generated_numeric,\n",
        "                \"is_correct\": is_correct\n",
        "            })\n",
        "\n",
        "    # final accuracy computation\n",
        "    accuracy = (correct_count / total_count) if total_count > 0 else 0.0\n",
        "\n",
        "    print(f\"Evaluation Complete: Correct = {correct_count}, Total = {total_count}, Accuracy = {accuracy:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"correct_count\": correct_count,\n",
        "        \"total_count\": total_count,\n",
        "        \"results\": results_list\n",
        "    }"
      ],
      "metadata": {
        "id": "2JDTTtEat5m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the zero-shot evaluation process.\n",
        "    \"\"\"\n",
        "    # --- Configuration ---\n",
        "    model_name = \"unsloth/gemma-3-1b-it-bnb-4bit\"\n",
        "    dataset_split = \"test\"\n",
        "    num_eval_samples = None # performs evaluation for the entire dataset_split\n",
        "    max_generation_tokens = 200\n",
        "    evaluation_batch_size=128\n",
        "\n",
        "    output_csv_file = f\"{model_name.replace('/', '_')}_gsm8k_{dataset_split}_zero_shot_results.csv\"\n",
        "    output_plot_file = f\"{model_name.replace('/', '_')}_gsm8k_{dataset_split}_zero_shot_accuracy.png\"\n",
        "\n",
        "    # 1. Load Model\n",
        "    model, tokenizer = load_model()\n",
        "\n",
        "    # 2. Prepare Data\n",
        "    evaluation_dataset = prepare_dataset(split=dataset_split)\n",
        "\n",
        "    #3. Evaluate\n",
        "    evaluation_results = evaluate_zero_shot(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        evaluation_dataset,\n",
        "        max_new_tokens=max_generation_tokens,\n",
        "        num_samples=num_eval_samples,\n",
        "        batch_size=evaluation_batch_size,\n",
        "    )\n",
        "\n",
        "    # 4. Save Results\n",
        "    print(\"\\n--- Evaluation Summary ---\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Dataset: GSM8K ({dataset_split} split)\")\n",
        "    print(f\"Batch Size: {evaluation_batch_size}\")\n",
        "    print(f\"Samples Evaluated: {evaluation_results['total_count']}\")\n",
        "    print(f\"Accuracy (Exact Match): {evaluation_results['accuracy']:.4f}\")\n",
        "    print(f\"Correct Answers: {evaluation_results['correct_count']}\")\n",
        "    print(\"-------------------------\\n\")\n",
        "\n",
        "    # Save results to CSV\n",
        "    try:\n",
        "        results_df = pd.DataFrame(evaluation_results['results'])\n",
        "        results_df.to_csv(output_csv_file, index=False)\n",
        "        print(f\"Detailed results saved to: {output_csv_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving results to CSV: {e}\")\n",
        "\n",
        "    # plotting the accuracy\n",
        "    try:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.bar(['Zero-shot Accuracy'], [evaluation_results['accuracy']], color='lightcoral')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'GSM8K Zero-shot Performance\\n({model_name})', fontsize=10)\n",
        "        plt.ylim(0, max(0.1, evaluation_results['accuracy'] * 1.2))\n",
        "        plt.text(0, evaluation_results['accuracy'], f'{evaluation_results[\"accuracy\"]:.4f}', ha='center', va='bottom')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_plot_file)\n",
        "        print(f\"Accuracy plot saved to: {output_plot_file}\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating plot: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "52967c9c5309444dbc7acbe57c19fafd",
            "7eb3e14882414e14a17810a1a1739918",
            "62aeb6bacb1e46a1ab472356e5f9fd5f",
            "0557a7119b6a4a109a7f5946f31f8547",
            "63f1726d65c6469fa2a958da030284ad",
            "6e48421c80cf43c3b861acdb3864b16d",
            "c8cc984eea594c4d8c34784a039d1c04",
            "7e0b60ff6a3340bfac3389fa8d99dc97",
            "f9e223282d1e42d6a24a2cec98e1ce78",
            "034ab55c5f9d4f1cb54e4c1c37ce1fe5",
            "bb78f7b21e8244e9a20dbdb726a5f4cd",
            "ce6fae7689f4480a991b7d8814da0f03",
            "ed371bd17aa6439e8bbdb717ecc59017",
            "5bb8eac2d67741a499116b2beb8e05f5",
            "c70ca4d07fdf400abba8136e6898f4ee",
            "b8873a785b6149618424c9800176fd92",
            "f62a15de4aad4d5798c9882864d1f855",
            "37620a8476bd482c90af8a413b256c1c",
            "1e485d053c2c43f5b121ce9229bd0d9d",
            "08bea0ec4eb04158b659dfb732ee288f",
            "73626a8f24ce440fba6241633d0cbb22",
            "627579979b6840a8918e0c006414c820"
          ]
        },
        "id": "0Pjz2XVCuHze",
        "outputId": "21712e9b-7d41-4388-9dad-a002e41701e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.4.7: Fast Gemma3 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Loading and preparing gsm8k dataset (split: test)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Formatting test data:   0%|          | 0/1319 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52967c9c5309444dbc7acbe57c19fafd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset preparation complete. 1319 examples formatted.\n",
            "Evaluating on the full dataset (1319 samples).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating Batches (Size 128):   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce6fae7689f4480a991b7d8814da0f03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Complete: Correct = 303, Total = 1319, Accuracy = 0.2297\n",
            "\n",
            "--- Evaluation Summary ---\n",
            "Model: unsloth/gemma-3-1b-it-bnb-4bit\n",
            "Dataset: GSM8K (test split)\n",
            "Batch Size: 128\n",
            "Samples Evaluated: 1319\n",
            "Accuracy (Exact Match): 0.2297\n",
            "Correct Answers: 303\n",
            "-------------------------\n",
            "\n",
            "Detailed results saved to: unsloth_gemma-3-1b-it-bnb-4bit_gsm8k_test_zero_shot_results.csv\n",
            "Accuracy plot saved to: unsloth_gemma-3-1b-it-bnb-4bit_gsm8k_test_zero_shot_accuracy.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zGrSJD3E2xPg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}