# Reinforcement Learning Evokes Reasoning in Small Language Models

Team Name: Digital Dragons
Contributors: Abhay Nandiraju, Ayesha Khatun, Maksim Kulik, Matthew Hernandez

> **Note** The scope of this project involves the following points: experiment with fine-tuning a reasoning model with reinforcement learning, track progress by evaluating on GSM8K benchmark, and assess the capability of reasoning in LLMs.

This project was created for the purpose of applying current techniques in the Machine Learning world to stay up-to-data with recent advancements. Are LLMs genuinely capable of true logical reasoning?

## Project Structure
```bash
			│── logs/
            │   ├── baseline/            # Logs for baseline model
            │   └── model_reasoning/     # Logs for model with reasoning
            │── src/
            │   ├── config/              # Configuration for models
            │   ├── notebooks/           # Code for experiments
            │   └── tasks/               # Helper task for modular coding
            │── tests/                   # Unit & integration tests
            │── README.md                # Project overview and setup instructions
            │── project_charter.txt      # Short document stating project details
            │── requirements.txt         # Requirements for project

```

## Setup 
TODO
- Direct attention to Google Colab (baselines & final model)

## Quick Start
TODO
- possibly load the final model for the prof and either evaluate a single sample/samples



